{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''               \n",
    "Scrapes for phone and emails and places in     \n",
    "spreadsheet.                                   \n",
    "Python 3 required                              \n",
    "'''\n",
    "\n",
    "import re\n",
    "from urllib.request import urlopen, Request\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "from openpyxl import Workbook\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "save_excel = True #Change to \"True\" to save email into Excel\n",
    "\n",
    "book = Workbook()\n",
    "sheet = book.active\n",
    "\n",
    "\n",
    "def start_scrape(page, name_the_file):\n",
    "\n",
    "    print(\"\\n\\nWebpage is currently being scrapped... please wait...\")\n",
    "       \n",
    "    scrape = BeautifulSoup(page, 'html.parser')\n",
    "    scrape = scrape.get_text()\n",
    "    \n",
    "    phone_numbers = set(re.findall(r\"((?:\\d{3}|\\(\\d{3}\\))?(?:\\s|-|\\.)?\\d{3}(?:\\s|-|\\.)\\d{4})\", scrape)) #\"set\" removes duplicates\n",
    "    emails = set(re.findall(r\"[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,3}\", scrape))\n",
    "\n",
    "    nodupnumber = len(list(phone_numbers))\n",
    "    nodupemail = len(list(emails))\n",
    "\n",
    "    dupnumber = len(list(re.findall(r\"((?:\\d{3}|\\(\\d{3}\\))?(?:\\s|-|\\.)?\\d{3}(?:\\s|-|\\.)\\d{4})\", scrape))) \n",
    "    dupemail = len(list(re.findall(r\"[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,3}\", scrape)))\n",
    "\n",
    "    number_of_dup_number = int(dupnumber) - int(nodupnumber) \n",
    "    number_of_dup_email = int(dupemail) - int(nodupemail)\n",
    "\n",
    "    email_list = list(emails)\n",
    "\n",
    "    if len(phone_numbers) == 0:\n",
    "        print(\"No phone number(s) found.\")\n",
    "\n",
    "        print(\"-----------------------------\\n\")\n",
    "    else:\n",
    "        count = 1\n",
    "        for item in phone_numbers:\n",
    "            print(\"Phone number #\" + str(count) + ': ' + item)\n",
    "            count += 1\n",
    "\n",
    "    print(\"-----------------------------\\n\")\n",
    "\n",
    "    if len(emails) == 0:\n",
    "        print(\"No email address(es) found.\")\n",
    "        print(\"-----------------------------\\n\")\n",
    "    else:\n",
    "        count = 1\n",
    "        for item in emails:\n",
    "            print('Email address #' + str(count) + ': ' + item)\n",
    "            count += 1\n",
    "\n",
    "    if save_excel:\n",
    "        for row in zip(email_list):\n",
    "            sheet.append(row)\n",
    "        excel_file = (name_the_file + \".xlsx\")\n",
    "        book.save(excel_file) \n",
    "       \n",
    "    print(\"\\nDuplicates have been removed from list.\")\n",
    "    print(\"Total phone numbers: \", nodupnumber)\n",
    "    print(\"Total email addresses: \", nodupemail)\n",
    "    print(\"There were \" + str(number_of_dup_number) + \" duplicate phone numbers.\")\n",
    "    print(\"There were \" + str(number_of_dup_email) + \" duplicate email addresses.\")\n",
    "\n",
    "    if save_excel:\n",
    "        print(\"\\n\\nData has been stored inside of an Excel spreadsheet named: \"\n",
    "              + excel_file + \" in this directory: \" + os.getcwd())\n",
    "        mod_time = os.stat(excel_file).st_mtime\n",
    "        print(\"\\nCompleted at: \" + str(datetime.fromtimestamp(mod_time)))\n",
    "        print(\"\\nSize of file: \" + str(os.stat(excel_file).st_size) + \" KB\")\n",
    "\n",
    "def main():\n",
    "\n",
    "    webpage = input(\"Paste the webpage you would like to scrape (include http/https): \")\n",
    "\n",
    "    if save_excel:\n",
    "        name_the_file = input(\"Name the file you would like to save the data in (don't include .xlsx): \")\n",
    "    save_excel=True\n",
    "    try:\n",
    "        page = urlopen(webpage) \n",
    "        start_scrape(page)\n",
    "    except:\n",
    "        hdr = {'User-Agent': 'Mozilla/5.0'}\n",
    "        req = Request(webpage, headers=hdr)\n",
    "        page = urlopen(req)\n",
    "        start_scrape(page, name_the_file)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
